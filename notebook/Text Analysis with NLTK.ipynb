{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1d9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddade7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1afb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaa199",
   "metadata": {},
   "source": [
    "## Import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5227d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6169f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truncation = pd.read_csv('../dataset/Truncations.csv').set_index('index')\n",
    "truncation = df_truncation.Truncation.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348bd3e",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21371d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d2642",
   "metadata": {},
   "source": [
    "The regex tokenizer used here separates the words of a contiguous string into a list consisting of words only. \"\\w+\" means that all word characters contiguous are turned into a list element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eab4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = nltk.tokenize.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504cccd",
   "metadata": {},
   "source": [
    "Stemming is a set of algorithms for determining the root of words. For example, the root of the words \"paint\", \"painted\", \"painting\" is the same. However, since algorithms are used, incorrect word stems can also be calculated. It is not uncommon to get results like \"peopl\" for \"peoples\" or \"poeple\". Depending on the algorithm, the stemming can also become too strong because too much is taken away from the word. In this case we talk about overstemming.\n",
    "\n",
    "An alternative approach is called lemmatization. Here the correct infinitive is taken from a stored guard book. This leads of course to the fact that not every word can be converted into its infinitive, since the lexicon is limited. In the following we use a lemmatization, because we want to build Wordclouds, which should contain real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c60f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEMMATIZER = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1924d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(x):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([0-9])\",\" \",x).split())   \n",
    "\n",
    "truncations_re = re.compile('(%s)' % '|'.join(truncation.keys()))\n",
    "\n",
    "#define function to expand contractions and showcase\n",
    "def expand_contractions(s, contractions = truncation):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return truncations_re.sub(replace, s)\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    return ' '.join([i for i in x.split() if i not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "170ed7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN = True\n",
    "\n",
    "if CLEAN:\n",
    "    for df in [train, test]:\n",
    "        df['text'] = df['text'].str.lower()\n",
    "        df['text'] = df['text'].apply(expand_contractions)\n",
    "        df['text'] = df['text'].apply(strip)\n",
    "        df['text'] = df['text'].apply(remove_stopwords)\n",
    "        df['text'] = df['text'].apply(LEMMATIZER.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f769b",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ace8bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = train.loc[train.target==0, 'text'].to_list()\n",
    "t = train.loc[train.target==1, 'text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just_real = [w for w in T if w not in F]\n",
    "# just_fake = [w for w in F if w not in T]\n",
    "# Just_Real = nltk.probability.FreqDist()\n",
    "# Just_Fake = nltk.probability.FreqDist()\n",
    "\n",
    "# for w in just_real:\n",
    "#     Just_Real[w] +=1\n",
    "\n",
    "# for w in just_fake:\n",
    "#     Just_Fake[w] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "863b3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_list=[]\n",
    "t_list=[]\n",
    "for i in [f, t]:\n",
    "    for r in range(0,len(i)):\n",
    "        if i == f:\n",
    "            f_list.extend(i[r].split())\n",
    "        else:\n",
    "            t_list.extend(i[r].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a34c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
