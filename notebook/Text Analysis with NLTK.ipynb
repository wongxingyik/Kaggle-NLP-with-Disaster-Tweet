{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1d9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddade7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1afb97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecaa199",
   "metadata": {},
   "source": [
    "## Import Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5227d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6169f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_truncation = pd.read_csv('../dataset/Truncations.csv').set_index('index')\n",
    "truncation = df_truncation.Truncation.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e348bd3e",
   "metadata": {},
   "source": [
    "## Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21371d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "STOPWORDS = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d2642",
   "metadata": {},
   "source": [
    "The regex tokenizer used here separates the words of a contiguous string into a list consisting of words only. \"\\w+\" means that all word characters contiguous are turned into a list element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eab4117",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = nltk.tokenize.RegexpTokenizer(r\"\\w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d504cccd",
   "metadata": {},
   "source": [
    "Stemming is a set of algorithms for determining the root of words. For example, the root of the words \"paint\", \"painted\", \"painting\" is the same. However, since algorithms are used, incorrect word stems can also be calculated. It is not uncommon to get results like \"peopl\" for \"peoples\" or \"poeple\". Depending on the algorithm, the stemming can also become too strong because too much is taken away from the word. In this case we talk about overstemming.\n",
    "\n",
    "An alternative approach is called lemmatization. Here the correct infinitive is taken from a stored guard book. This leads of course to the fact that not every word can be converted into its infinitive, since the lexicon is limited. In the following we use a lemmatization, because we want to build Wordclouds, which should contain real words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c60f2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEMMATIZER = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1924d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(x):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|([0-9])\",\" \",x).split())   \n",
    "\n",
    "truncations_re = re.compile('(%s)' % '|'.join(truncation.keys()))\n",
    "\n",
    "#define function to expand contractions and showcase\n",
    "def expand_contractions(s, contractions = truncation):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return truncations_re.sub(replace, s)\n",
    "\n",
    "def remove_stopwords(x):\n",
    "    return ' '.join([i for i in x.split() if i not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "170ed7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN = True\n",
    "\n",
    "if CLEAN:\n",
    "    for df in [train, test]:\n",
    "        df['text'] = df['text'].str.lower()\n",
    "        df['text'] = df['text'].apply(expand_contractions)\n",
    "        df['text'] = df['text'].apply(strip)\n",
    "        df['text'] = df['text'].apply(remove_stopwords)\n",
    "        df['text'] = df['text'].apply(LEMMATIZER.lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6f769b",
   "metadata": {},
   "source": [
    "## WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ace8bbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = train.loc[train.target==0, 'text'].to_list()\n",
    "t = train.loc[train.target==1, 'text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a9b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_tostring(s):\n",
    "    # initialize an empty string\n",
    "    str1 = \"\" \n",
    "    \n",
    "    # traverse in the string  \n",
    "    for ele in s: \n",
    "        str1 += ' '\n",
    "        str1 += ele  \n",
    "    \n",
    "    # return string  \n",
    "    return str1 \n",
    "\n",
    "F = list_tostring(f)\n",
    "T = list_tostring(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38924be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def just(F, T):\n",
    "    F_list = F.split()\n",
    "    T_list = T.split()\n",
    "    \n",
    "    just_F = list_tostring([w for w in F_list if w not in T_list])\n",
    "    just_T = list_tostring([w for w in T_list if w not in F_list])\n",
    "    \n",
    "    return just_F, just_T\n",
    "\n",
    "just_F, just_T = just(F, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84a34c0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Uncomment to generate wordcloud image\n",
    "# for i in [just_F, just_T]:\n",
    "#     wordcloud = WordCloud(width = 800, height = 800,\n",
    "#                     background_color ='black',\n",
    "#                     stopwords = STOPWORDS,\n",
    "#                     min_font_size = 10).generate(i)\n",
    "\n",
    "#     # plot the WordCloud image                      \n",
    "#     plt.figure(figsize = (7, 7), facecolor = None)\n",
    "#     plt.imshow(wordcloud)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.tight_layout(pad = 0)\n",
    "\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f93f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Just_Real = nltk.probability.FreqDist()\n",
    "Just_Fake = nltk.probability.FreqDist()\n",
    "\n",
    "for w in just_T.split():\n",
    "    Just_Real[w] +=1\n",
    "\n",
    "for w in just_F.split():\n",
    "    Just_Fake[w] +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "044722f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plotfreq(text):\n",
    "#     Just_Rea"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
