{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b20b978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e06916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461c6ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e92f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENABLE_GPU = False\n",
    "# if ENABLE_GPU:\n",
    "#     from tensorflow.python.client import device_lib\n",
    "#     tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1e1aa",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c161a457",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../dataset/train.csv')\n",
    "test = pd.read_csv('../dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8efa82",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b283e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test.id\n",
    "train_id = train.id\n",
    "\n",
    "#drop id and location\n",
    "c = ['id', 'location']\n",
    "train = train.drop(columns=c)\n",
    "test = test.drop(columns=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d428f",
   "metadata": {},
   "source": [
    "#### Missing Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f866fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing keywords with unknown\n",
    "train['keyword'] = train.keyword.fillna('unknown')\n",
    "test['keyword'] = test.keyword.fillna('unknown')\n",
    "\n",
    "#fill keyword to tweets\n",
    "train['text'] = train['text'] + ' ' + train['keyword']\n",
    "test['text'] = test['text'] + ' ' + test['keyword']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3646c05",
   "metadata": {},
   "source": [
    "#### Truncations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef68c1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Truncation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ain't</th>\n",
       "      <td>am not / are not / is not / has not / have not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aren't</th>\n",
       "      <td>are not / am not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't</th>\n",
       "      <td>cannot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can't've</th>\n",
       "      <td>cannot have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>'cause</th>\n",
       "      <td>because</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Truncation\n",
       "index                                                   \n",
       "ain't     am not / are not / is not / has not / have not\n",
       "aren't                                  are not / am not\n",
       "can't                                             cannot\n",
       "can't've                                     cannot have\n",
       "'cause                                           because"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_truncation = pd.read_csv('../dataset/Truncations.csv').set_index('index')\n",
    "df_truncation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f715c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"ain't\": 'am not / are not / is not / has not / have not',\n",
       " \"aren't\": 'are not / am not',\n",
       " \"can't\": 'cannot',\n",
       " \"can't've\": 'cannot have',\n",
       " \"'cause\": 'because',\n",
       " \"could've\": 'could have',\n",
       " \"couldn't\": 'could not',\n",
       " \"couldn't've\": 'could not have',\n",
       " \"didn't\": 'did not',\n",
       " \"doesn't\": 'does not',\n",
       " \"don't\": 'do not',\n",
       " \"hadn't\": 'had not',\n",
       " \"hadn't've\": 'had not have',\n",
       " \"hasn't\": 'has not',\n",
       " \"haven't\": 'have not',\n",
       " \"he'd\": 'he had / he would',\n",
       " \"he'd've\": 'he would have',\n",
       " \"he'll\": 'he shall / he will',\n",
       " \"he'll've\": 'he shall have / he will have',\n",
       " \"he's\": 'he has / he is',\n",
       " \"how'd\": 'how did',\n",
       " \"how'd'y\": 'how do you',\n",
       " \"how'll\": 'how will',\n",
       " \"how's\": 'how has / how is / how does',\n",
       " \"I'd\": 'I had / I would',\n",
       " \"I'd've\": 'I would have',\n",
       " \"I'll\": 'I shall / I will',\n",
       " \"I'll've\": 'I shall have / I will have',\n",
       " \"I'm\": 'I am',\n",
       " \"I've\": 'I have',\n",
       " \"isn't\": 'is not',\n",
       " \"it'd\": 'it had / it would',\n",
       " \"it'd've\": 'it would have',\n",
       " \"it'll\": 'it shall / it will',\n",
       " \"it'll've\": 'it shall have / it will have',\n",
       " \"it's\": 'it has / it is',\n",
       " \"let's\": 'let us',\n",
       " \"ma'am\": 'madam',\n",
       " \"mayn't\": 'may not',\n",
       " \"might've\": 'might have',\n",
       " \"mightn't\": 'might not',\n",
       " \"mightn't've\": 'might not have',\n",
       " \"must've\": 'must have',\n",
       " \"mustn't\": 'must not',\n",
       " \"mustn't've\": 'must not have',\n",
       " \"needn't\": 'need not',\n",
       " \"needn't've\": 'need not have',\n",
       " \"o'clock\": 'of the clock',\n",
       " \"oughtn't\": 'ought not',\n",
       " \"oughtn't've\": 'ought not have',\n",
       " \"shan't\": 'shall not',\n",
       " \"sha'n't\": 'shall not',\n",
       " \"shan't've\": 'shall not have',\n",
       " \"she'd\": 'she had / she would',\n",
       " \"she'd've\": 'she would have',\n",
       " \"she'll\": 'she shall / she will',\n",
       " \"she'll've\": 'she shall have / she will have',\n",
       " \"she's\": 'she has / she is',\n",
       " \"should've\": 'should have',\n",
       " \"shouldn't\": 'should not',\n",
       " \"shouldn't've\": 'should not have',\n",
       " \"so've\": 'so have',\n",
       " \"so's\": 'so as / so is',\n",
       " \"that'd\": 'that would / that had',\n",
       " \"that'd've\": 'that would have',\n",
       " \"that's\": 'that has / that is',\n",
       " \"there'd\": 'there had / there would',\n",
       " \"there'd've\": 'there would have',\n",
       " \"there's\": 'there has / there is',\n",
       " \"they'd\": 'they had / they would',\n",
       " \"they'd've\": 'they would have',\n",
       " \"they'll\": 'they shall / they will',\n",
       " \"they'll've\": 'they shall have / they will have',\n",
       " \"they're\": 'they are',\n",
       " \"they've\": 'they have',\n",
       " \"to've\": 'to have',\n",
       " \"wasn't\": 'was not',\n",
       " \"we'd\": 'we had / we would',\n",
       " \"we'd've\": 'we would have',\n",
       " \"we'll\": 'we will',\n",
       " \"we'll've\": 'we will have',\n",
       " \"we're\": 'we are',\n",
       " \"we've\": 'we have',\n",
       " \"weren't\": 'were not',\n",
       " \"what'll\": 'what shall / what will',\n",
       " \"what'll've\": 'what shall have / what will have',\n",
       " \"what're\": 'what are',\n",
       " \"what's\": 'what has / what is',\n",
       " \"what've\": 'what have',\n",
       " \"when's\": 'when has / when is',\n",
       " \"when've\": 'when have',\n",
       " \"where'd\": 'where did',\n",
       " \"where's\": 'where has / where is',\n",
       " \"where've\": 'where have',\n",
       " \"who'll\": 'who shall / who will',\n",
       " \"who'll've\": 'who shall have / who will have',\n",
       " \"who's\": 'who has / who is',\n",
       " \"who've\": 'who have',\n",
       " \"why's\": 'why has / why is',\n",
       " \"why've\": 'why have',\n",
       " \"will've\": 'will have',\n",
       " \"won't\": 'will not',\n",
       " \"won't've\": 'will not have',\n",
       " \"would've\": 'would have',\n",
       " \"wouldn't\": 'would not',\n",
       " \"wouldn't've\": 'would not have',\n",
       " \"y'all\": 'you all',\n",
       " \"y'all'd\": 'you all would',\n",
       " \"y'all'd've\": 'you all would have',\n",
       " \"y'all're\": 'you all are',\n",
       " \"y'all've\": 'you all have',\n",
       " \"you'd\": 'you had / you would',\n",
       " \"you'd've\": 'you would have',\n",
       " \"you'll\": 'you shall / you will',\n",
       " \"you'll've\": 'you shall have / you will have',\n",
       " \"you're\": 'you are',\n",
       " \"you've\": 'you have'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncation = df_truncation.Truncation.to_dict()\n",
    "truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd25911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am not / are not / is not / has not / have not'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compile all contraction words\n",
    "truncations_re = re.compile('(%s)' % '|'.join(truncation.keys()))\n",
    "\n",
    "\n",
    "#define function to expand contractions and showcase\n",
    "def expand_contractions(s, contractions = truncation):\n",
    "#     print(s)\n",
    "    def replace(match):\n",
    "#         print( contractions[match.group(0)])\n",
    "        return contractions[match.group(0)]\n",
    "    return truncations_re.sub(replace, s)\n",
    "\n",
    "expand_contractions(\"ain't\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b46645a",
   "metadata": {},
   "source": [
    "#### Strip Sentence\n",
    "remove URL, symbol, emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0e9c79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barbados Bridgetown JAMAICA Two cars set ablaze SANTA CRUZ Head of the St Elizabeth Police Superintende'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def strip(x):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x).split())\n",
    "\n",
    "strip('@shawn Titanic #tragedy could have been prevented Economic Times: Telegraph.co.uk Titanic tragedy could have been prevented... http://bet.ly/tuN2wx')\n",
    "strip('Barbados #Bridgetown JAMAICA Â‰Ã›Ã’ Two cars set ablaze: SANTA CRUZ Â‰Ã›Ã“ Head of the St Elizabeth Police Superintende...  http://t.co/wDUEaj8Q4J')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb18684",
   "metadata": {},
   "source": [
    "#### Remove Stopwords\n",
    "\n",
    "'hello a world' -> 'hello world'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d912121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this removes stopwords\n",
    "def remove_stopwords(x):\n",
    "    return ' '.join([i for i in x.split() if i not in STOPWORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364cd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncommend to see STOPWORDS\n",
    "# STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97718a12",
   "metadata": {},
   "source": [
    "#### Preprocess Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e175df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLEAN_TWEETS = True\n",
    "if CLEAN_TWEETS:\n",
    "    for df in [train, test]:\n",
    "        df['text'] = df['text'].apply(expand_contractions)\n",
    "        df['text'] = df['text'].apply(strip)\n",
    "        df['text'] = df['text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600084b",
   "metadata": {},
   "source": [
    "## Meta Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cee17d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(x):\n",
    "    x = x.split()\n",
    "    return np.mean([len(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23c12e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for df in [train, test]:\n",
    "#     #Word Count\n",
    "#     #'hello hello a world' -> 4\n",
    "#     df['word count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "    \n",
    "#     #Character Count\n",
    "#     #'hello hello a world' -> 19 (including space) \n",
    "#     df['character count'] = df['text'].apply(lambda x: len(x))\n",
    "    \n",
    "#     #Average word length\n",
    "#     #'hello hello a world' -> 4\n",
    "#     df['average word length'] = df['text'].apply(average_word_length)\n",
    "    \n",
    "#     #Unique word count\n",
    "#     #'hello hello a world' -> 3 unique words\n",
    "#     df['unique word count'] = df['text'].apply(lambda x: len(set(x.split())))\n",
    "    \n",
    "#     #Stopword count\n",
    "#     #'hello hello a world' -> 1 stopword\n",
    "#     df['stopword count'] = df['text'].apply(lambda x: len([i for i in x.lower().split() if i in STOPWORDS]))\n",
    "    \n",
    "#     #Stopword ratio\n",
    "#     #'hello hello a world' -> 1/4 = 0.25\n",
    "#     df['stopword ratio'] = df['stopword count'] / df['word count']\n",
    "    \n",
    "#     #URL count\n",
    "#     #'hello hello a world' -> 0 URL count\n",
    "#     df['url count'] = df['text'].apply(lambda x: len([i for i in x.lower().split() if 'http' in i or 'https' in i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23dea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.target\n",
    "train = train.drop(columns='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d196399",
   "metadata": {},
   "source": [
    "#### Standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec254ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdsc = StandardScaler()\n",
    "# train.iloc[:, 2:] = stdsc.fit_transform(train.iloc[:, 2:])\n",
    "# test.iloc[:, 2:] = stdsc.transform(test.iloc[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ce956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fa6d2b3",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9a8bf41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(train, y, \n",
    "                                                  train_size=0.7, \n",
    "                                                  random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229c22d2",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8242f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "TOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a2d758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode: [101, 7592, 2088, 999, 102]\n",
      "Decode: [CLS] hello world! [SEP]\n"
     ]
    }
   ],
   "source": [
    "enc = TOKENIZER.encode(\"Hello World!\")\n",
    "dec = TOKENIZER.decode(enc)\n",
    "print(\"Encode: \" + str(enc))\n",
    "print(\"Decode: \" + str(dec))\n",
    "\n",
    "#In bert tokenizer,\n",
    "# CLS is the reserved token to represent the start of sequence\n",
    "# while SEP separate segment or sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaadabf",
   "metadata": {},
   "source": [
    "## BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6c88dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7bb6da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#get BERT layer\n",
    "bert_base = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7fc0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(data,maximum_len) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "  \n",
    "\n",
    "    for i in range(len(data.text)):\n",
    "        encoded = TOKENIZER.encode_plus(data.text[i],\n",
    "                                        add_special_tokens=True,\n",
    "                                        max_length=maximum_len,\n",
    "                                        pad_to_max_length=True,\n",
    "                                        return_attention_mask=True)\n",
    "      \n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "        \n",
    "    return np.array(input_ids),np.array(attention_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33107118",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4886808",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "EPOCHS = 2\n",
    "\n",
    "#we will not be using metadata \n",
    "USE_META = False\n",
    "\n",
    "ADD_DENSE = False\n",
    "DENSE_DIM = 64\n",
    "\n",
    "ADD_DROPOUT = True\n",
    "DROPOUT = .2\n",
    "\n",
    "TRAIN_BASE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6506812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_layer, learning_rate, use_meta = USE_META, add_dense = ADD_DENSE,\n",
    "               dense_dim = DENSE_DIM, add_dropout = ADD_DROPOUT, dropout = DROPOUT):\n",
    "    \n",
    "    \n",
    "    input_ids = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    attention_masks = tf.keras.Input(shape=(60,),dtype='int32')\n",
    "    \n",
    "    \n",
    "    \n",
    "    transformer_layer = model_layer([input_ids,attention_masks])\n",
    "    \n",
    "    \n",
    "    output = transformer_layer[1]\n",
    "    \n",
    "        \n",
    "    if add_dense:\n",
    "        print(\"Training with additional dense layer...\")\n",
    "        output = tf.keras.layers.Dense(dense_dim,activation='relu')(output)\n",
    "    \n",
    "    \n",
    "    if add_dropout:\n",
    "        print(\"Training with dropout...\")\n",
    "        output = tf.keras.layers.Dropout(dropout)(output)\n",
    "    \n",
    "    \n",
    "    output = tf.keras.layers.Dense(1,activation='sigmoid')(output)\n",
    "    \n",
    "    \n",
    "    print(\"Training without meta-data...\")\n",
    "    model = tf.keras.models.Model(inputs = [input_ids,attention_masks],outputs = output)\n",
    "\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca67336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\wxyik\\anaconda3\\envs\\python3_9_6\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2198: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Tweets...\n",
      "Tweets encoded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Encoding Tweets...')\n",
    "train_input_ids,train_attention_masks = bert_encode(train,60)\n",
    "test_input_ids,test_attention_masks = bert_encode(test,60)\n",
    "print('Tweets encoded')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3947f192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1df791e9e20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x1df791e9e20>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Training with dropout...\n",
      "Training without meta-data...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 60)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,483,009\n",
      "Trainable params: 109,483,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wxyik\\anaconda3\\envs\\python3_9_6\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "BERT_base = build_model(bert_base, learning_rate = 1e-5)\n",
    "BERT_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07f0a8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint('base_model.h5', monitor='val_loss', save_best_only = True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8d4c73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "381/381 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.7865WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "381/381 [==============================] - 1628s 4s/step - loss: 0.4730 - accuracy: 0.7865 - val_loss: 0.4118 - val_accuracy: 0.8194\n",
      "Epoch 2/2\n",
      "381/381 [==============================] - 1567s 4s/step - loss: 0.3735 - accuracy: 0.8489 - val_loss: 0.3864 - val_accuracy: 0.8299\n"
     ]
    }
   ],
   "source": [
    "history = BERT_base.fit([train_input_ids,train_attention_masks], y, validation_split = .2, epochs = EPOCHS, callbacks = [checkpoint], batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16234c04",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de28137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "prediction = BERT_base.predict([test_input_ids,test_attention_masks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "066f93d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fe5144c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(columns=['id', 'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "917be766",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['id'] = test_id\n",
    "submission['target'] = np.round(prediction).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eaca3720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       1\n",
       "4  11       1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6e671c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../submission/submission_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e2b8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
